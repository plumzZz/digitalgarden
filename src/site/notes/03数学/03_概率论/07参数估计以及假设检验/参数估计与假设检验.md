---
{"tags":[],"dg-publish":true,"permalink":"/03数学/03_概率论/07参数估计以及假设检验/参数估计与假设检验/","dgPassFrontmatter":true}
---

---
![Pasted image 20250918095609.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918095609.png)
![Pasted image 20250918095621.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918095621.png)
# 参数估计
## 一、点估计的概念

设总体  $X$  的分布函数  $F(x; \theta)$  的形式已知,  $\theta$  是待估参数,  $X_{1}, X_{2}, \dots , X_{n}$  是来自总体  $X$  的简单随机样本。所谓的点估计就是构造一个适当的统计量  $\hat{\theta} (X_{1}, X_{2}, \dots , X_{n})$ ,用  $\hat{\theta}$  估计相应的参数  $\theta$ ,这个统计量  $\hat{\theta}$  就称为  $\theta$  的**估计量**。若  $x_{1}, x_{2}, \dots , x_{n}$  为样本的一组观察值,则称  $\hat{\theta} (x_{1}, x_{2}, \dots , x_{n})$  为  $\theta$  的一个**估计值**。
## 二、点估计的方法

### (一) 矩估计法
矩估计法思想:1900年英国统计学家K·Pearson提出了一个替换原则——**用样本矩去替换总体矩**。如果总体  $X$  的  $k$  (  $k$  为正整数)阶原点矩存在,则对任意给定的  $\epsilon > 0$ ,当样本容量  $n$  趋于无穷大时,有  $\lim_{n \to \infty} P\left\{\left| \frac{1}{n} \sum_{i = 1}^{n} X_{i}^{k} - E(X^{k}) \right| < \epsilon \right\} = 1$ ,
即样本的  $k$  **阶原点矩依概率收敛**于总体的  $k$  阶原点矩,故用样本的  $k$  阶原点矩  $A_{k} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}^{k}$  作为总体  $k$  阶原点矩  $\mu_{k} = E(X^{k})$  的估计,令  $A_{k} = \mu_{k}$ ,即  $\frac{1}{n} \sum_{i = 1}^{n} X_{i}^{k} = E(X^{k}) (k = 1, 2, \dots)$ ,对于不同的  $k$  值,可以得到若干个等式,从中求得参数  $\theta$  的估计量  $\hat{\theta}$  是样本  $X_{1}, X_{2}, \dots , X_{n}$  的函数,称为参数的矩估计量。若  $x_{1}, x_{2}, \dots , x_{n}$  为样本的一组观察值。
具体用法如下：
	![Pasted image 20250918164046.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918164046.png)![Pasted image 20250918164144.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918164144.png)
	


### (二) 最大似然估计法

![Pasted image 20250918165044.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918165044.png)
1. **离散型总体的最大似然估计**
设总体  $X$  是离散型随机变量,概率分布为  $P(X = t_{i}) = p(t_{i};\theta),i = 1,2,\dots ,$
其中  $\theta \in \Theta$  为待估参数,设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $X$  的样本,  $x_{1},x_{2},\dots ,x_{n}$  是样本值,函数
$L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}p(x_{i},\theta)$ 
为样本  $x_{1},x_{2},\dots ,x_{n}$  的似然函数.
如果  $\hat{\theta}\in \Theta$  ,使得  $L(\hat{\theta}) = \max_{\theta \in \Theta}L(\theta)$  ,这样的 $\hat{\theta}$ 与$x_{1},x_{2},\dots ,x_{n}$ 有关,记作  $\hat{\theta} (x_{1},x_{2},\dots ,x_{n})$  称为未知参数  $\theta$  的最大似然估计值,相应的统计量  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  称为  $\theta$  的最大似然估计量.

2. **连续型总体的最大似然估计**
设总体  $X$  具有概率密度函数  $f(x;\theta)$  ,其中  $\theta \in \Theta$  为待估参数,设  $X_{1},X_{2},\dots ,X_{n}$  是来自总体  $X$  的样本  $x_{1},x_{2},\dots ,x_{n}$  是样本值,
称函数  $L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}f(x_{i},\theta)$  
为样本  $x_{1},x_{2},\dots ,x_{n}$  的**似然函数**.
如果  $\hat{\theta}\in \Theta$  ,使得  $L(\hat{\theta}) = \max_{\theta \in \Theta}L(\theta)$  ,这样的  $\hat{\theta}$  与  $x_{1},x_{2},\dots ,x_{n}$  有关,记作  $\hat{\theta} (x_{1},x_{2},\dots ,x_{n})$  称为未知参数  $\theta$  的最大似然估计值,相应的统计量  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  称为 $\theta$ 的最大似然估计量.
**写出似然函数**
$L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}p(x_{i},\theta)$  (离散型);
$L(\theta) = L(x_{1},x_{2},\dots ,x_{n};\theta) = \prod_{i = 1}^{n}f(x_{i},\theta)$  (连续型).
**取对数** $\ln L(\theta)$
将  $\ln L(\theta)$  对$\theta$ 求导$\frac{\mathrm{d}\ln L(\theta)}{\mathrm{d}\theta}$ ;
判断方程组  $\frac{\mathrm{d}\ln L}{\mathrm{d}\theta} = 0$  是否有解,
若有唯一的解,则其解即为所求最大似然估计;
若有不同的解,则根据题干条件取舍;
若无解,则最大似然估计常在  $\theta$  取值的端点上取得.
![Pasted image 20250918170110.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918170110.png)
![Pasted image 20250918170123.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918170123.png)

## 估计量的评选标准
### (一)无偏性
如果估计量  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  的数学期望  $E(\hat{\theta})$  存在,且对于任意  $\hat{\theta} \in \Theta$ ,有  $E(\hat{\theta}) = \theta$ ,则称 $\hat{\theta}$ 是未知参数 $\theta$ 的无偏估计量.
### (二)有效性
设  $\hat{\theta}_{1}(X_{1},X_{2},\dots ,X_{n})$  和  $\hat{\theta}_{2}(X_{1},X_{2},\dots ,X_{n})$  都是未知参数  $\theta$  的无偏估计量,如果对于任意  $\hat{\theta} \in \Theta$ ,有  $D(\hat{\theta}_{1}) \leqslant D(\hat{\theta}_{2})$ ,则称  $\hat{\theta}_{1}(X_{1},X_{2},\dots ,X_{n})$  比  $\hat{\theta}_{2}(X_{1},X_{2},\dots ,X_{n})$  更有效.
### (三)一致性(相合性)
只针对大样本
设  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  为未知参数  $\theta$  的估计量,如果对于任意  $\theta \in \Theta$ ,当  $n \to \infty$  时, $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  依概率收敛于  $\theta$ ,
则称  $\hat{\theta} (X_{1},X_{2},\dots ,X_{n})$  为未知参数  $\theta$  的一致估计量或相合估计量。
![Pasted image 20250918210604.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918210604.png)

**良哥解读**
因矩估计是由样本的  $k$  阶原点矩依概率收敛到总体的  $k$  阶原点矩建立方程得到,故若  $\hat{\theta}$  为未知参数  $\theta$  的矩估计量,则其一定为一致估计量.




## 置信区间（区间估计）
### (一)定义
设总体  $X$  的分布函数为$F(x;\theta)$ ,其中$\theta$ 为未知参数,从总体  $X$  中抽取样本  $X_{1},X_{2},\dots ,X_{n}$  对于给定的  $\alpha (0< \alpha < 1)$ ,如果两个统计量  $\theta_{1} = \theta_{1}(X_{1},X_{2},\dots ,X_{n})$ , $\theta_{2} = \theta_{2}(X_{1},X_{2},\dots ,X_{n})$ ,满足  $P(\theta_{1}< \theta < \theta_{2}) = 1 - \alpha$ ,则称随机区间  $(\theta_{1},\theta_{2})$  为参数  $\theta$  的置信水平(或置信度)是  $1 - \alpha$  的置信区间(或区间估计),简称为  $\theta$  的  $1 - \alpha$  的置信区间, $\theta_{1}$  和  $\theta_{2}$  分别称为置信下限和置信上限.
![Pasted image 20250918212319.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918212319.png)
### (二)一个正态总体的区间估计
设  $X \sim N(\mu ,\sigma^{2})$ ,从总体$X$ 中抽取样本$X_{1},X_{2},\dots ,X_{n}$ ,样本均值为  $\overline{X}$ ,样本方差为$S^{2}$ .
![Pasted image 20250918213913.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918213913.png)
推理过程：
	![Pasted image 20250918214054.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214054.png)![Pasted image 20250918214015.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214015.png)
	![Pasted image 20250918214256.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214256.png)
	![Pasted image 20250918214331.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214331.png)
	![Pasted image 20250918214455.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214455.png)
	![Pasted image 20250918214815.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214815.png)
	![Pasted image 20250918214934.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918214934.png)
	
### (三)两个正态总体参数的区间估计

设两个总体  $X\sim N(\mu_{1},\sigma_{1}^{2})$  ,  $Y\sim N(\mu_{2},\sigma_{2}^{2})$  相互独立,从总体  $X$  中抽取样本  $X_{1},X_{2},\dots ,X_{n_{1}}$  样本均值为  $\overline{X}$  ,样本方差为  $S_{1}^{2}$  ,从总体  $Y$  中抽取样本  $Y_{1},Y_{2},\dots ,Y_{n_{2}}$  ,样本均值为  $\overline{Y}$  ,样本方差为 $S_{2}^{2}$

<table><tr><td colspan="2">未知参数</td><td>1-α置信区间</td></tr><tr><td rowspan="2">μ1-μ2</td><td>σ12,σ22
已知</td><td>(X-Y-Uα/2Aσ12+σ22,n1,n2,X-Y+Uα/2Aσ12+σ22,n1,n2)</td></tr><tr><td>σ12,σ22
未知,但
σ12=σ22</td><td>(X-Y-tα/2(n1+n2-2)Sw√(1/n1+1/n2),X-Y-tα/2(n1+n2-2)Sw√(1/n1+1/n2))</td></tr><tr><td rowspan="2">σ12/σ22</td><td>μ1,μ2
已知</td><td>(n2∑n1(Xi-μ1)2
n1∑n1(Xi-μ1)2
n1∑(Yj-μ2)2
Fα/2(n1,n2),n1∑(Yj-μ2)2
Fα/2(n1,n2),n1∑(Yj-μ2)2
n1∑(Yj-μ2)2)</td></tr><tr><td>μ1,μ2
未知</td><td>(S21/S22)1/(S21-S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)1/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S22)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(T2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(S2)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2)/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS22)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS22)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS2222)2/(SS22222)2/(SS22222)2/(SS222222)2/(SS222222)2/(SS2222222)2/(SS2222222)2/(SS22222222)2/(SS222222222)2/(SS2222222222)2/(SS22222222222)2/(SS222222222222)2/(SS22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222220000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000</td></tr></table>

其中  $S_{w} = \sqrt{\frac{(n_{1} - 1)S_{1}^{2} + (n_{2} - 1)S_{2}^{2}}{n_{1} + n_{2} - 2}}.$

# 假设检验

## 基本概念
**(一)假设**
关于总体分布的未知参数的假设,所提出的假设称为零假设或原假设,记为  $H_{0}$ ,对立于零假设的假设称为对立假设或备择假设,记为  $H_{1}$
![Pasted image 20250918215408.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918215408.png)


**(二)假设检验**
小概率原理与显著性水平

根据样本,按照一定规则判断所做假设  $H_{0}$  的真伪,并作出接受还是拒绝接受  $H_{0}$  的决定.
(三)**假设检验的原理**(**实际推断原理**)
小概率事件在一次试验中几乎是不可能发生的,
(四)**两类错误**
拒绝实际真的假设  $H_{0}$  (弃真)称为第一类错误;
接受实际不真的假设  $H_{0}$  (纳伪)称为第二类错误
![Pasted image 20250918221109.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918221109.png)

## 显著性检验
在确定检验法则时,应尽可能地使犯两类错误的概率都小些,但是一般来说,当样本容量取定后,
如果要减少犯某一类错误的概率,则犯另一类错误的概率往往要增大,要使犯两类错误的概率都减少,只好加大样本容量,在给定样本容量的情况下,我们总是控制犯第一类错误的概率,使它不大于给定的  $\alpha (0< \alpha < 1)$ ,这种检验问题称为显著性检验问题,给定的  $\alpha$  称为显著性水平,通常取  $\alpha = 0.1, 0.05, 0.01, 0.001$ .
在对假设  $H_{0}$  进行检验时,常使用某个统计量  $T$ ,称为检验统计量,当检验统计量在某个区域  $W$  取值时,我们就拒绝假设  $H_{0}$ ,称区域  $W$  为拒绝域.

## (六)显著性检验的一般步骤
1. 根据问题要求提出原假设  $H_{0}$  和对立假设  $H_{1}$ ;
2. 给出显著性水平  $\alpha (0< \alpha < 1)$  及样本容量  $n$ ;
3. 确定检验统计量及拒绝域形式;
4. 按犯第一类错误的概率等于  $\alpha$ ,求出拒绝域  $W$ ;
5. 根据样本值计算检验统计量  $T$  的观测值  $t$ ,当  $t \in W$  时,拒绝原假设  $H_{0}$ ,否则接受原假设  $H_{0}$ .

## 正态总体参数的假设检验
设显著性水平为  $\alpha$ ,单个正态总体为  $N(\mu , \sigma^{2})$  的参数的假设检验列表如下:
<table><tr><td rowspan="2">检验参数</td><td rowspan="2">情形</td><td colspan="2">假设</td><td>检验统计量</td><td>为真时检验统计量的分布</td><td>拒绝域</td></tr><tr><td>H0</td><td>H1</td><td></td><td></td><td></td></tr><tr><td rowspan="2">μ</td><td>σ²已知</td><td>μ=μ0</td><td>μ≠μ0</td><td>U= X-μ0/σ/√n</td><td>N(0,1)</td><td>|U|≥uα/2</td></tr><tr><td>σ²未知</td><td>μ=μ0</td><td>μ≠μ0</td><td>Tt= X-μ0/S/√n</td><td>t(n-1)</td><td>|T|≥tα/2(n-1)</td></tr><tr><td rowspan="2">σ²</td><td>μ已知</td><td>σ²=σ²0</td><td>σ²≠σ²0</td><td>χ²= 1/σ²0∑n(i=1)(Xi-μ)²</td><td>χ²(n)</td><td>χ²≤χ1-α/2(n)或χ²≥χα/2(n)</td></tr><tr><td>μ未知</td><td>σ²=σ²0</td><td>σ²≠σ²0</td><td>χ²=(n-1)S²/σ²0</td><td>χ²(n-1)</td><td>χ²≤χ1-α/2(n-1)或χ²≥χα/2(n-1)</td></tr></table>


![Pasted image 20250918220227.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220227.png)
![Pasted image 20250918220314.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220314.png)
![Pasted image 20250918220619.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220619.png)
![Pasted image 20250918220652.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220652.png)
![Pasted image 20250918220841.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220841.png)
![Pasted image 20250918220821.png](/img/user/01%E9%99%84%E4%BB%B6/Pasted%20image%2020250918220821.png)